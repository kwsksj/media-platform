#!/usr/bin/env python3
"""
å­¤ç«‹R2ç”»åƒï¼ˆNotionã«ç´ã¥ã„ã¦ã„ãªã„ç”»åƒï¼‰ã‚’Notionãƒšãƒ¼ã‚¸ã«ç´ã¥ã‘ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å‰å›ã®ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ã§R2ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãŒã€Notioné€£æºãŒ
ç„¡åŠ¹ã«ãªã£ã¦ã„ãŸãŸã‚ã«ã€Œå­¤ç«‹ã€çŠ¶æ…‹ã«ãªã£ã¦ã—ã¾ã£ãŸç”»åƒã‚’å¯¾è±¡ã«ã€
ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã¨ç…§ã‚‰ã—åˆã‚ã›ã¦Notionãƒšãƒ¼ã‚¸ã‚’ä½œæˆãƒ»æ›´æ–°ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
  # dry-runï¼ˆç¢ºèªã®ã¿ï¼‰
  python scripts/link_orphaned_images.py /path/to/WorksPhotes

  # å®Ÿè¡Œ
  python scripts/link_orphaned_images.py /path/to/WorksPhotes --execute
"""

import argparse
import logging
import re
import sys
from pathlib import Path
from urllib.parse import unquote, urlparse

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT_DIR / "src"))

from auto_post.config import Config  # noqa: E402
from auto_post.grouping import IMAGE_EXTENSIONS, get_photo_metadata  # noqa: E402
from auto_post.notion_db import NotionDB  # noqa: E402
from auto_post.r2_storage import R2Storage  # noqa: E402
from auto_post.schedule_lookup import ScheduleLookup  # noqa: E402

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("botocore").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

KNOWN_R2_PREFIXES = (
    "photos/",
    "photos-light/",
    "images/",
    "images-light/",
    "uploads/",
    "uploads-light/",
)


def _extract_original_filename(r2_key: str) -> str:
    """R2ã‚­ãƒ¼ã‹ã‚‰ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºã™ã‚‹ã€‚"""
    basename = r2_key.split("/")[-1]
    match = re.match(r"^\d{14}_(.+)$", basename)
    if match:
        return match.group(1)
    return basename


def _get_page_image_urls(page: dict) -> list[str]:
    """ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºã™ã‚‹ã€‚"""
    files_prop = page.get("properties", {}).get("ç”»åƒ", {})
    files = files_prop.get("files", [])
    urls = []
    for f in files:
        if f.get("type") == "external":
            url = f.get("external", {}).get("url", "")
            if url:
                urls.append(url)
        elif f.get("type") == "file":
            url = f.get("file", {}).get("url", "")
            if url:
                urls.append(url)
    return urls


def _url_to_r2_key(url: str, public_url: str) -> str | None:
    """ç”»åƒURLã‹ã‚‰R2ã‚­ãƒ¼ã‚’æŠ½å‡ºã™ã‚‹ã€‚"""
    if not url:
        return None
    public_url = (public_url or "").rstrip("/")
    if public_url and url.startswith(f"{public_url}/"):
        key = url[len(public_url) :].lstrip("/")
        return unquote(key) if key else None
    parsed = urlparse(url)
    path = unquote(parsed.path.lstrip("/"))
    if path.startswith(KNOWN_R2_PREFIXES):
        return path
    return None


def _list_r2_keys_with_prefix(r2: R2Storage, prefix: str) -> list[str]:
    keys: list[str] = []
    client = r2._create_client()
    continuation_token = None

    while True:
        kwargs = {
            "Bucket": r2.config.bucket_name,
            "Prefix": prefix,
            "MaxKeys": 1000,
        }
        if continuation_token:
            kwargs["ContinuationToken"] = continuation_token

        response = client.list_objects_v2(**kwargs)
        for obj in response.get("Contents", []):
            key = obj.get("Key", "")
            if key:
                keys.append(key)

        if response.get("IsTruncated"):
            continuation_token = response.get("NextContinuationToken")
        else:
            break

    return keys


def _list_all_r2_keys(
    r2: R2Storage,
    prefixes: tuple[str, ...] = KNOWN_R2_PREFIXES,
) -> set[str]:
    all_keys: set[str] = set()
    for prefix in prefixes:
        all_keys.update(_list_r2_keys_with_prefix(r2, prefix=prefix))
    return all_keys


def main():
    parser = argparse.ArgumentParser(description="å­¤ç«‹R2ç”»åƒã‚’Notionã«é€£æº")
    parser.add_argument("folder", type=Path, help="ãƒ­ãƒ¼ã‚«ãƒ«ã® WorksPhotes ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹")
    parser.add_argument("--execute", action="store_true", help="å®Ÿéš›ã«Notioné€£æºã‚’å®Ÿè¡Œ")
    parser.add_argument("--env-file", type=Path, default=ROOT_DIR / ".env")
    args = parser.parse_args()

    dry_run = not args.execute
    root_folder = args.folder

    if not root_folder.exists():
        print(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {root_folder}")
        return

    print("=" * 60)
    if dry_run:
        print("ğŸ” DRY-RUN ãƒ¢ãƒ¼ãƒ‰ (Notionæ›´æ–°ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“)")
    else:
        print("âš ï¸  EXECUTE ãƒ¢ãƒ¼ãƒ‰ (å®Ÿéš›ã«Notioné€£æºã‚’å®Ÿè¡Œã—ã¾ã™)")
        confirm = input("æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ")
        if confirm.strip().lower() != "yes":
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
            return
    print("=" * 60)

    config = Config.load(env_file=args.env_file, allow_missing_instagram=True)
    notion = NotionDB(
        config.notion.token,
        config.notion.database_id,
        config.notion.tags_database_id,
    )
    r2 = R2Storage(config.r2)
    public_url = config.r2.public_url or ""

    try:
        schedule_lookup = ScheduleLookup(config)
    except Exception as e:
        logger.warning(f"Could not initialize ScheduleLookup: {e}")
        schedule_lookup = None

    # ------------------------------------------------
    # Step 1: ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å -> æ‰€å±ãƒ•ã‚©ãƒ«ãƒ€åã®ãƒãƒƒãƒ—ä½œæˆ
    # ------------------------------------------------
    print(f"\nğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {root_folder}")
    local_file_candidates: dict[str, list[Path]] = {}

    for path in root_folder.rglob("*"):
        if path.suffix.lower() in IMAGE_EXTENSIONS and not path.name.startswith("."):
            local_file_candidates.setdefault(path.name, []).append(path)

    local_count = sum(len(paths) for paths in local_file_candidates.values())
    print(f"  ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒæ•°: {local_count}")

    # ------------------------------------------------
    # Step 2: Notionå…¨ãƒšãƒ¼ã‚¸ã‹ã‚‰å‚ç…§ã•ã‚Œã¦ã„ã‚‹R2ã‚­ãƒ¼ã‚’å–å¾—
    # ------------------------------------------------
    print("\nğŸ“‹ Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­...")
    all_pages = notion.list_database_pages(notion.database_id)
    notion_r2_keys = set()

    for page in all_pages:
        if page.get("archived"):
            continue
        for url in _get_page_image_urls(page):
            key = _url_to_r2_key(url, public_url)
            if key:
                notion_r2_keys.add(key)

    print(f"  Notionã‹ã‚‰å‚ç…§ã•ã‚Œã¦ã„ã‚‹ç”»åƒæ•°: {len(notion_r2_keys)}")

    # ------------------------------------------------
    # Step 3: R2å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆã‹ã‚‰ã€Œå­¤ç«‹ã‚­ãƒ¼ã€ã‚’ç‰¹å®š
    # ------------------------------------------------
    print("\nğŸ“¦ R2ãƒã‚±ãƒƒãƒˆã‹ã‚‰å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’å–å¾—ä¸­...")
    all_r2_keys = _list_all_r2_keys(r2)
    joined_prefixes = ", ".join(KNOWN_R2_PREFIXES)
    orphaned_r2_keys = all_r2_keys - notion_r2_keys

    print(f"  å¯¾è±¡prefix: {joined_prefixes}")
    print(f"  R2å…¨ä½“: {len(all_r2_keys)}")
    print(f"  å­¤ç«‹ç”»åƒ: {len(orphaned_r2_keys)} ä»¶")

    if not orphaned_r2_keys:
        print("\nâœ… å­¤ç«‹ã—ãŸç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # ------------------------------------------------
    # Step 4: å­¤ç«‹ã‚­ãƒ¼ã‚’æ‰€å±ãƒ•ã‚©ãƒ«ãƒ€ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    # ------------------------------------------------
    # folder_name -> {"urls": [...], "paths": [...]}
    link_plan: dict[str, dict[str, list]] = {}
    unmatched_keys = []

    for key in orphaned_r2_keys:
        fname = _extract_original_filename(key)
        candidates = local_file_candidates.get(fname, [])
        if not candidates:
            unmatched_keys.append(key)
            continue

        if len(candidates) > 1:
            candidates = sorted(candidates)
            logger.warning(
                "Multiple local matches for %s; using %s",
                fname,
                candidates[0],
            )
        matched_path = candidates[0]
        folder_name = matched_path.parent.name

        if folder_name not in link_plan:
            link_plan[folder_name] = {"urls": [], "paths": []}

        url = f"{public_url}/{key}" if public_url else key
        link_plan[folder_name]["urls"].append(url)
        link_plan[folder_name]["paths"].append(matched_path)

    print("\n" + "=" * 60)
    print("ğŸ“Š é€£æºè¨ˆç”»ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"  é€£æºå¯èƒ½ãƒ•ã‚©ãƒ«ãƒ€æ•°: {len(link_plan)}")
    print(f"  ãƒ­ãƒ¼ã‚«ãƒ«ã«å­˜åœ¨ã›ãšåˆ¤åˆ¥ä¸èƒ½ãªç”»åƒ: {len(unmatched_keys)} ä»¶")

    for folder_name, data in link_plan.items():
        urls = data["urls"]
        print(f"\n  ğŸ“‚ {folder_name} ({len(urls)}æš)")
        for url in urls[:3]:
            print(f"    + {url}")
        if len(urls) > 3:
            print(f"    ... ä»– {len(urls) - 3} ä»¶")

    if not link_plan:
        print("\nâœ… é€£æºå¯èƒ½ãªç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ------------------------------------------------
    # Step 5: å®Ÿè¡Œ (Notioné€£æº)
    # ------------------------------------------------
    if dry_run:
        print("\n" + "=" * 60)
        print("ğŸ” DRY-RUNå®Œäº†ã€‚å®Ÿéš›ã«Notionã¸é€£æºã™ã‚‹ã«ã¯ --execute ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚")
        print("=" * 60)
        return

    print("\nâ³ Notioné€£æºã‚’å®Ÿè¡Œä¸­...")
    notion_created = 0
    notion_updated = 0
    errors = 0

    for folder_name, data in link_plan.items():
        new_urls = data["urls"]
        local_paths = data["paths"]
        print(f"\n  ğŸ“‚ {folder_name} ã®å‡¦ç†ä¸­...")

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã®æœ€å¤ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»£è¡¨æ—¥æ™‚ã¨ã™ã‚‹
        folder_timestamp = None
        for path in local_paths:
            ts, _, _ = get_photo_metadata(path)
            if ts:
                if folder_timestamp is None or ts < folder_timestamp:
                    folder_timestamp = ts
        try:
            page_id = notion.find_page_by_title(folder_name)
            if page_id:
                # æ—¢å­˜ãƒšãƒ¼ã‚¸ã«è¿½è¨˜
                page = notion.client.pages.retrieve(page_id)
                files_prop = page.get("properties", {}).get("ç”»åƒ", {})
                existing_files = files_prop.get("files", [])

                files_payload = existing_files.copy()
                for i, url in enumerate(new_urls):
                    files_payload.append(
                        {
                            "type": "external",
                            "name": f"image_{len(existing_files) + i + 1}",
                            "external": {"url": url},
                        }
                    )

                notion.client.pages.update(
                    page_id=page_id, properties={"ç”»åƒ": {"files": files_payload}}
                )
                notion_updated += 1
                logger.info(
                    "Updated existing Notion page: %s (+%s images)",
                    folder_name,
                    len(new_urls),
                )

            else:
                # æ–°è¦ãƒšãƒ¼ã‚¸ä½œæˆ
                classroom = None
                if schedule_lookup and folder_timestamp:
                    classroom = schedule_lookup.lookup_classroom(folder_timestamp)

                notion.add_work(
                    work_name=folder_name,
                    image_urls=new_urls,
                    creation_date=folder_timestamp,
                    classroom=classroom,
                )
                notion_created += 1
                logger.info(
                    "Created new Notion page: %s (%s images, Date: %s)",
                    folder_name,
                    len(new_urls),
                    folder_timestamp,
                )

        except Exception as e:
            errors += 1
            logger.error(f"Failed to link Notion page for {folder_name}: {e}")

    print("\n" + "=" * 60)
    print("ğŸ‰ é€£æºå®Œäº†")
    print("=" * 60)
    print(f"  Notionæ–°è¦ä½œæˆ: {notion_created} ãƒšãƒ¼ã‚¸")
    print(f"  Notionãƒšãƒ¼ã‚¸æ›´æ–°: {notion_updated} ãƒšãƒ¼ã‚¸")
    print(f"  ã‚¨ãƒ©ãƒ¼: {errors} ä»¶")


if __name__ == "__main__":
    main()
