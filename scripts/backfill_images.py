#!/usr/bin/env python3
"""
æ¬ ã‘ç”»åƒãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆR2ãƒ•ã‚¡ã‚¤ãƒ«åçªåˆæ–¹å¼ï¼‰

ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã¨ã€R2ä¸Šã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¯”è¼ƒã—ã€
R2ã«ã¾ã ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
ãã®å¾Œã€ç”»åƒãŒå…ˆç”Ÿç”¨UIï¼ˆNotionï¼‰ã«è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®è¦ªãƒ•ã‚©ãƒ«ãƒ€åã‚’
ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ãŸNotionãƒšãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆã¾ãŸã¯æ—¢å­˜ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ï¼‰ã—ã¦ç´ã¥ã‘ã‚‹ã€‚

ä½¿ã„æ–¹:
  # dry-runï¼ˆç¢ºèªã®ã¿ï¼‰
  python scripts/backfill_images.py /path/to/WorksPhotes

  # å®Ÿè¡Œ
  python scripts/backfill_images.py /path/to/WorksPhotes --execute
"""

import argparse
import logging
import mimetypes
import re
import sys
from datetime import datetime
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT_DIR / "src"))

from auto_post.config import Config
from auto_post.grouping import IMAGE_EXTENSIONS, get_photo_metadata
from auto_post.notion_db import NotionDB
from auto_post.r2_storage import R2Storage
from auto_post.schedule_lookup import ScheduleLookup

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("botocore").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)


def _extract_original_filename(r2_key: str) -> str:
    """R2ã‚­ãƒ¼ã‹ã‚‰ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºã™ã‚‹ã€‚
    R2ã‚­ãƒ¼å½¢å¼: photos/{timestamp14}_{filename}
    """
    basename = r2_key.split("/")[-1]
    match = re.match(r"^\d{14}_(.+)$", basename)
    if match:
        return match.group(1)
    return basename


def _list_all_r2_keys(r2: R2Storage, prefix: str = "photos/") -> list[str]:
    """R2ãƒã‚±ãƒƒãƒˆå†…ã®å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’ãƒªã‚¹ãƒˆã™ã‚‹ã€‚"""
    keys = []
    client = r2._create_client()
    continuation_token = None

    while True:
        kwargs = {
            "Bucket": r2.config.bucket_name,
            "Prefix": prefix,
            "MaxKeys": 1000,
        }
        if continuation_token:
            kwargs["ContinuationToken"] = continuation_token

        response = client.list_objects_v2(**kwargs)
        for obj in response.get("Contents", []):
            key = obj.get("Key", "")
            if key:
                keys.append(key)

        if response.get("IsTruncated"):
            continuation_token = response.get("NextContinuationToken")
        else:
            break

    return keys


def main():
    parser = argparse.ArgumentParser(
        description="æ¬ ã‘ç”»åƒãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆR2ãƒ•ã‚¡ã‚¤ãƒ«åçªåˆï¼‰"
    )
    parser.add_argument(
        "folder",
        type=Path,
        help="ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="å®Ÿéš›ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ (æŒ‡å®šã—ãªã„å ´åˆã¯dry-run)",
    )
    parser.add_argument(
        "--env-file",
        type=Path,
        default=ROOT_DIR / ".env",
        help=".envãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹",
    )
    args = parser.parse_args()

    dry_run = not args.execute
    root_folder = args.folder

    if not root_folder.exists():
        print(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {root_folder}")
        return

    if dry_run:
        print("=" * 60)
        print("ğŸ” DRY-RUN ãƒ¢ãƒ¼ãƒ‰ (ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“)")
        print("=" * 60)
    else:
        print("=" * 60)
        print("âš ï¸  EXECUTE ãƒ¢ãƒ¼ãƒ‰ (å®Ÿéš›ã«R2ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™)")
        print("=" * 60)
        confirm = input("æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ")
        if confirm.strip().lower() != "yes":
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
            return

    # è¨­å®šèª­ã¿è¾¼ã¿
    config = Config.load(env_file=args.env_file, allow_missing_instagram=True)
    notion = NotionDB(
        config.notion.token,
        config.notion.database_id,
        config.notion.tags_database_id,
    )
    r2 = R2Storage(config.r2)
    public_url = config.r2.public_url or ""

    try:
        schedule_lookup = ScheduleLookup(config)
    except Exception as e:
        logger.warning(f"Could not initialize ScheduleLookup: {e}")
        schedule_lookup = None

    # ------------------------------------------------
    # Step 1: ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒã‚’ã‚¹ã‚­ãƒ£ãƒ³
    # ------------------------------------------------
    print(f"\nğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {root_folder}")
    local_images: dict[str, Path] = {}  # filename -> path

    for path in root_folder.rglob("*"):
        if path.suffix.lower() in IMAGE_EXTENSIONS and not path.name.startswith("."):
            local_images[path.name] = path

    print(f"  ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒæ•°: {len(local_images)}")

    # ------------------------------------------------
    # Step 2: R2å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
    # ------------------------------------------------
    print("\nğŸ“¦ R2ãƒã‚±ãƒƒãƒˆã‹ã‚‰å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’å–å¾—ä¸­...")
    all_r2_keys = _list_all_r2_keys(r2, prefix="photos/")
    print(f"  R2 photos/ ç·æ•°: {len(all_r2_keys)}")

    # R2ã«ã‚ã‚‹ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
    r2_filenames = set()
    for key in all_r2_keys:
        fname = _extract_original_filename(key)
        r2_filenames.add(fname)

    print(f"  R2ä¸Šã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«å: {len(r2_filenames)}")

    # ------------------------------------------------
    # Step 3: æ¬ ã‘ç”»åƒã‚’ç‰¹å®š
    # ------------------------------------------------
    # ãƒ•ã‚©ãƒ«ãƒ€å˜ä½ã§æ¬ ã‘ç”»åƒã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    missing_by_folder: dict[str, list[Path]] = {}
    for fname, path in sorted(local_images.items()):
        if fname not in r2_filenames:
            folder_name = path.parent.name
            if folder_name not in missing_by_folder:
                missing_by_folder[folder_name] = []
            missing_by_folder[folder_name].append(path)

    missing_images = [path for paths in missing_by_folder.values() for path in paths]
    already_count = len(local_images) - len(missing_images)

    print(f"\n" + "=" * 60)
    print("ğŸ“Š ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«å¯¾è±¡ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"  ãƒ­ãƒ¼ã‚«ãƒ«ç”»åƒ:     {len(local_images)}")
    print(f"  R2ã«æ—¢å­˜:         {already_count}")
    print(f"  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡:  {len(missing_images)}")

    if len(missing_images) <= 100:
        for folder_name, paths in missing_by_folder.items():
            print(f"\n  ğŸ“‚ {folder_name} ({len(paths)}ä»¶):")
            for path in paths:
                print(f"    + {path.name}")
    else:
        print(f"  (ä»¶æ•°ãŒå¤šã„ãŸã‚å…ˆé ­ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¡¨ç¤º)")
        count = 0
        for folder_name, paths in missing_by_folder.items():
            print(f"\n  ğŸ“‚ {folder_name} ({len(paths)}ä»¶):")
            for path in paths[:5]:
                print(f"    + {path.name}")
            if len(paths) > 5:
                print(f"    ... ä»– {len(paths) - 5} ä»¶")
            count += len(paths)
            if count >= 30:
                print(f"\n    ... ä»¥é™çœç•¥")
                break

    if not missing_images:
        print("\nâœ… å…¨ç”»åƒãŒR2ã«å­˜åœ¨ã—ã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ä¸è¦ã§ã™ã€‚")
        return

    # ------------------------------------------------
    # Step 4: å®Ÿè¡Œ
    # ------------------------------------------------
    if dry_run:
        print(f"\n" + "=" * 60)
        print("ğŸ” DRY-RUN å®Œäº†ã€‚å®Ÿéš›ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»Notioné€£æºã™ã‚‹ã«ã¯ --execute ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚")
        print(f"   python scripts/backfill_images.py {root_folder} --execute")
        print("=" * 60)
        return

    print(f"\nâ³ {len(missing_images)} ä»¶ã‚’R2ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼†Notioné€£æºä¸­...")
    uploaded = 0
    errors = 0
    notion_created = 0
    notion_updated = 0

    for folder_name, paths in missing_by_folder.items():
        print(f"\n  ğŸ“‚ {folder_name} ã®å‡¦ç†ä¸­...")
        new_urls = []

        # 1. R2ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        for path in paths:
            fname = path.name
            try:
                content = path.read_bytes()
                mime_type, _ = mimetypes.guess_type(str(path))
                if not mime_type:
                    mime_type = "image/jpeg"

                timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                key = f"photos/{timestamp}_{fname}"
                r2.upload(content, key, mime_type)

                if public_url:
                    url = f"{public_url}/{key}"
                else:
                    url = key

                new_urls.append(url)
                uploaded += 1
                logger.info(f"Uploaded: {fname} -> {key}")

            except Exception as e:
                errors += 1
                logger.error(f"Failed to upload {fname}: {e}")

        if not new_urls:
            continue

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã®æœ€å¤ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»£è¡¨æ—¥æ™‚ã¨ã™ã‚‹
        folder_timestamp = None
        for path in paths:
            ts, _, _ = get_photo_metadata(path)
            if ts:
                if folder_timestamp is None or ts < folder_timestamp:
                    folder_timestamp = ts

        # 2. Notionã¸é€£æº (ãƒšãƒ¼ã‚¸æ¤œç´¢ â†’ è¿½åŠ  or æ–°è¦ä½œæˆ)
        try:
            page_id = notion.find_page_by_title(folder_name)
            if page_id:
                # æ—¢å­˜ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯ã€ç¾åœ¨ã®ç”»åƒã‚’å–å¾—ã—ã¦è¿½è¨˜ã™ã‚‹
                page = notion.client.pages.retrieve(page_id)
                files_prop = page.get("properties", {}).get("ç”»åƒ", {})
                existing_files = files_prop.get("files", [])

                files_payload = existing_files.copy()
                for i, url in enumerate(new_urls):
                    files_payload.append({
                        "type": "external",
                        "name": f"image_{len(existing_files) + i + 1}",
                        "external": {"url": url}
                    })

                notion.client.pages.update(
                    page_id=page_id,
                    properties={"ç”»åƒ": {"files": files_payload}}
                )
                notion_updated += 1
                logger.info(f"Updated existing Notion page: {folder_name} (+{len(new_urls)} images)")

            else:
                # æ–°è¦ãƒšãƒ¼ã‚¸ä½œæˆ
                classroom = None
                if schedule_lookup and folder_timestamp:
                    classroom = schedule_lookup.lookup_classroom(folder_timestamp)

                notion.add_work(
                    work_name=folder_name,
                    image_urls=new_urls,
                    creation_date=folder_timestamp,
                    classroom=classroom,
                )
                notion_created += 1
                logger.info(f"Created new Notion page: {folder_name} ({len(new_urls)} images, Date: {folder_timestamp})")

        except Exception as e:
            errors += 1
            logger.error(f"Failed to link Notion page for {folder_name}: {e}")

    # ------------------------------------------------
    # çµæœã‚µãƒãƒªãƒ¼
    # ------------------------------------------------
    print(f"\n" + "=" * 60)
    print("ğŸ‰ ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«å®Œäº†")
    print("=" * 60)
    print(f"  R2ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {uploaded} ä»¶")
    print(f"  Notionæ–°è¦ä½œæˆ: {notion_created} ãƒšãƒ¼ã‚¸")
    print(f"  Notionæ›´æ–°æ›´æ–°: {notion_updated} ãƒšãƒ¼ã‚¸")
    print(f"  ã‚¨ãƒ©ãƒ¼: {errors} ä»¶")


if __name__ == "__main__":
    main()
